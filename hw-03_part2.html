<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kristi Manasil">

<title>hw-03</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="hw-03_part2_files/libs/clipboard/clipboard.min.js"></script>
<script src="hw-03_part2_files/libs/quarto-html/quarto.js"></script>
<script src="hw-03_part2_files/libs/quarto-html/popper.min.js"></script>
<script src="hw-03_part2_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="hw-03_part2_files/libs/quarto-html/anchor.min.js"></script>
<link href="hw-03_part2_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="hw-03_part2_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="hw-03_part2_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="hw-03_part2_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="hw-03_part2_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">hw-03</h1>
<p class="subtitle lead">Classification: Alternative Techniques</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Kristi Manasil </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="install-packages" class="level2">
<h2 class="anchored" data-anchor-id="install-packages"><strong>Install packages</strong></h2>
<p>Install the packages used in this chapter:</p>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: pacman</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: tidyverse</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.3     ✔ readr     2.1.4
✔ forcats   1.0.0     ✔ stringr   1.5.0
✔ ggplot2   3.4.3     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.0
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
</div>
<p>Show fewer digits</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction"><strong>Introduction</strong></h2>
<p>Many different <a href="https://en.wikipedia.org/wiki/Supervised_learning">classification algorithms</a> have been proposed in the literature. In this chapter, we will apply some of the more popular methods.</p>
</section>
<section id="training-and-test-data" class="level2">
<h2 class="anchored" data-anchor-id="training-and-test-data"><strong>Training and Test Data</strong></h2>
<p>I will use the Bird dataset which I created in part 1 of this assignment. The Bird dataset contains 17 (mostly logical) variables on 250 different observations for 5 bird species as a data frame with 16 columns with information about the presence of environmental factors when the observation occured.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 250
Columns: 17
$ species           &lt;chr&gt; "daejun", "daejun", "blujay", "bkcchi", "blujay", "b…
$ yard_type_landsca &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE…
$ yard_type_woods   &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FA…
$ hab_dcid_woods    &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FA…
$ hab_mixed_woods   &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE…
$ hab_park          &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ hab_water_fresh   &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FA…
$ hab_industrial    &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FA…
$ hab_agricultural  &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ hab_young_woods   &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ hab_swamp         &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ hab_marsh         &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ nearby_feeders    &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FA…
$ cats              &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ dogs              &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ humans            &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FA…
$ housing_density   &lt;int&gt; 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 3…</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 250
Columns: 17
$ species           &lt;fct&gt; daejun, daejun, blujay, bkcchi, blujay, blujay, daej…
$ yard_type_landsca &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE…
$ yard_type_woods   &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FA…
$ hab_dcid_woods    &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FA…
$ hab_mixed_woods   &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE…
$ hab_park          &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ hab_water_fresh   &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FA…
$ hab_industrial    &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FA…
$ hab_agricultural  &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ hab_young_woods   &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ hab_swamp         &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ hab_marsh         &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ nearby_feeders    &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FA…
$ cats              &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ dogs              &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
$ humans            &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FA…
$ housing_density   &lt;int&gt; 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 3…</code></pre>
</div>
</div>
<p>Test data is not used in the model building process and needs to be set aside purely for testing the model after it is completely built. Here I use 80% for training.</p>
</section>
<section id="fitting-different-classification-models-to-the-training-data" class="level2">
<h2 class="anchored" data-anchor-id="fitting-different-classification-models-to-the-training-data"><strong>Fitting Different Classification Models to the Training Data</strong></h2>
<p>Create a fixed sampling scheme (10-folds) so we can compare the fitted models later.</p>
<p>I am going to look at accuracy below as a primarily check of overall performance of these decision trees. While accuracy is not always a good indicator for performance, as it can be misleading, I believe it is useful in determine which models/trees might be best.</p>
<section id="conditional-inference-tree-decision-tree" class="level3">
<h3 class="anchored" data-anchor-id="conditional-inference-tree-decision-tree"><strong>Conditional Inference Tree (Decision Tree)</strong></h3>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Conditional Inference Tree 

202 samples
 16 predictor
  5 classes: 'amegfi', 'bkcchi', 'blujay', 'daejun', 'tuftit' 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 181, 182, 181, 181, 181, 184, ... 
Resampling results across tuning parameters:

  mincriterion  Accuracy  Kappa 
  0.010         0.415     0.2427
  0.255         0.470     0.2769
  0.500         0.408     0.2100
  0.745         0.470     0.2389
  0.990         0.390     0.0143

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was mincriterion = 0.745.</code></pre>
</div>
</div>
<p>These accuracy scores that range from 38 to 46% are not awesome. I expect that the plot below will show that these attributes are not good indicators of species.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Unlike the example, I only have the top node with a significant p value.</p>
</section>
<section id="c-4.5-decision-tree" class="level3">
<h3 class="anchored" data-anchor-id="c-4.5-decision-tree"><strong>C 4.5 Decision Tree</strong></h3>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>C4.5-like Trees 

202 samples
 16 predictor
  5 classes: 'amegfi', 'bkcchi', 'blujay', 'daejun', 'tuftit' 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 180, 181, 183, 182, 181, 183, ... 
Resampling results across tuning parameters:

  C      M  Accuracy  Kappa
  0.010  1  0.443     0.250
  0.010  2  0.443     0.253
  0.010  3  0.443     0.250
  0.010  4  0.468     0.270
  0.010  5  0.443     0.263
  0.133  1  0.500     0.308
  0.133  2  0.455     0.259
  0.133  3  0.455     0.277
  0.133  4  0.472     0.302
  0.133  5  0.488     0.318
  0.255  1  0.540     0.342
  0.255  2  0.437     0.245
  0.255  3  0.392     0.217
  0.255  4  0.480     0.302
  0.255  5  0.488     0.310
  0.378  1  0.565     0.379
  0.378  2  0.470     0.292
  0.378  3  0.470     0.326
  0.378  4  0.463     0.304
  0.378  5  0.493     0.317
  0.500  1  0.545     0.348
  0.500  2  0.470     0.292
  0.500  3  0.470     0.326
  0.500  4  0.463     0.304
  0.500  5  0.493     0.317

Accuracy was used to select the optimal model using the largest value.
The final values used for the model were C = 0.378 and M = 1.</code></pre>
</div>
</div>
<p>Based on accuracy the C45 may produce better results than the conditional inference tree, lets look closer.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>J48 pruned tree
------------------

housing_density &lt;= 3
|   hab_water_freshTRUE &lt;= 0
|   |   hab_marshTRUE &lt;= 0
|   |   |   hab_swampTRUE &lt;= 0
|   |   |   |   yard_type_woodsTRUE &lt;= 0
|   |   |   |   |   housing_density &lt;= 1: bkcchi (5.0/1.0)
|   |   |   |   |   housing_density &gt; 1
|   |   |   |   |   |   hab_parkTRUE &lt;= 0: daejun (5.0/2.0)
|   |   |   |   |   |   hab_parkTRUE &gt; 0
|   |   |   |   |   |   |   catsTRUE &lt;= 0
|   |   |   |   |   |   |   |   hab_dcid_woodsTRUE &lt;= 0
|   |   |   |   |   |   |   |   |   hab_mixed_woodsTRUE &lt;= 0: amegfi (4.0/2.0)
|   |   |   |   |   |   |   |   |   hab_mixed_woodsTRUE &gt; 0: blujay (4.0/1.0)
|   |   |   |   |   |   |   |   hab_dcid_woodsTRUE &gt; 0: amegfi (6.0/3.0)
|   |   |   |   |   |   |   catsTRUE &gt; 0
|   |   |   |   |   |   |   |   hab_industrialTRUE &lt;= 0: amegfi (3.0/1.0)
|   |   |   |   |   |   |   |   hab_industrialTRUE &gt; 0
|   |   |   |   |   |   |   |   |   hab_agriculturalTRUE &lt;= 0: daejun (1.0)
|   |   |   |   |   |   |   |   |   hab_agriculturalTRUE &gt; 0: tuftit (1.0)
|   |   |   |   yard_type_woodsTRUE &gt; 0
|   |   |   |   |   humansTRUE &lt;= 0
|   |   |   |   |   |   nearby_feedersTRUE &lt;= 0
|   |   |   |   |   |   |   hab_mixed_woodsTRUE &lt;= 0: amegfi (1.0)
|   |   |   |   |   |   |   hab_mixed_woodsTRUE &gt; 0: blujay (4.0/1.0)
|   |   |   |   |   |   nearby_feedersTRUE &gt; 0: bkcchi (1.0)
|   |   |   |   |   humansTRUE &gt; 0
|   |   |   |   |   |   dogsTRUE &lt;= 0
|   |   |   |   |   |   |   hab_parkTRUE &lt;= 0
|   |   |   |   |   |   |   |   catsTRUE &lt;= 0: bkcchi (1.0)
|   |   |   |   |   |   |   |   catsTRUE &gt; 0: daejun (5.0)
|   |   |   |   |   |   |   hab_parkTRUE &gt; 0
|   |   |   |   |   |   |   |   hab_dcid_woodsTRUE &lt;= 0: amegfi (1.0)
|   |   |   |   |   |   |   |   hab_dcid_woodsTRUE &gt; 0: bkcchi (1.0)
|   |   |   |   |   |   dogsTRUE &gt; 0
|   |   |   |   |   |   |   hab_mixed_woodsTRUE &lt;= 0
|   |   |   |   |   |   |   |   hab_dcid_woodsTRUE &lt;= 0
|   |   |   |   |   |   |   |   |   hab_industrialTRUE &lt;= 0: blujay (2.0)
|   |   |   |   |   |   |   |   |   hab_industrialTRUE &gt; 0: daejun (1.0)
|   |   |   |   |   |   |   |   hab_dcid_woodsTRUE &gt; 0: amegfi (2.0/1.0)
|   |   |   |   |   |   |   hab_mixed_woodsTRUE &gt; 0
|   |   |   |   |   |   |   |   hab_parkTRUE &lt;= 0
|   |   |   |   |   |   |   |   |   hab_industrialTRUE &lt;= 0: daejun (11.0/5.0)
|   |   |   |   |   |   |   |   |   hab_industrialTRUE &gt; 0: amegfi (4.0/1.0)
|   |   |   |   |   |   |   |   hab_parkTRUE &gt; 0
|   |   |   |   |   |   |   |   |   hab_industrialTRUE &lt;= 0: bkcchi (1.0)
|   |   |   |   |   |   |   |   |   hab_industrialTRUE &gt; 0: daejun (4.0/1.0)
|   |   |   hab_swampTRUE &gt; 0: daejun (7.0/2.0)
|   |   hab_marshTRUE &gt; 0
|   |   |   hab_swampTRUE &lt;= 0: bkcchi (9.0/2.0)
|   |   |   hab_swampTRUE &gt; 0: daejun (3.0/1.0)
|   hab_water_freshTRUE &gt; 0
|   |   yard_type_woodsTRUE &lt;= 0
|   |   |   hab_industrialTRUE &lt;= 0: daejun (11.0/5.0)
|   |   |   hab_industrialTRUE &gt; 0: blujay (1.0)
|   |   yard_type_woodsTRUE &gt; 0
|   |   |   hab_dcid_woodsTRUE &lt;= 0
|   |   |   |   humansTRUE &lt;= 0
|   |   |   |   |   hab_parkTRUE &lt;= 0: bkcchi (2.0)
|   |   |   |   |   hab_parkTRUE &gt; 0: tuftit (2.0)
|   |   |   |   humansTRUE &gt; 0
|   |   |   |   |   hab_industrialTRUE &lt;= 0
|   |   |   |   |   |   hab_marshTRUE &lt;= 0
|   |   |   |   |   |   |   housing_density &lt;= 1: daejun (3.0/1.0)
|   |   |   |   |   |   |   housing_density &gt; 1: tuftit (16.0/11.0)
|   |   |   |   |   |   hab_marshTRUE &gt; 0
|   |   |   |   |   |   |   catsTRUE &lt;= 0: bkcchi (7.0/3.0)
|   |   |   |   |   |   |   catsTRUE &gt; 0: blujay (2.0/1.0)
|   |   |   |   |   hab_industrialTRUE &gt; 0
|   |   |   |   |   |   hab_parkTRUE &lt;= 0: amegfi (3.0/1.0)
|   |   |   |   |   |   hab_parkTRUE &gt; 0: daejun (1.0)
|   |   |   hab_dcid_woodsTRUE &gt; 0
|   |   |   |   yard_type_landscaTRUE &lt;= 0
|   |   |   |   |   hab_agriculturalTRUE &lt;= 0: bkcchi (3.0/1.0)
|   |   |   |   |   hab_agriculturalTRUE &gt; 0: amegfi (3.0/1.0)
|   |   |   |   yard_type_landscaTRUE &gt; 0
|   |   |   |   |   hab_industrialTRUE &lt;= 0
|   |   |   |   |   |   hab_young_woodsTRUE &lt;= 0
|   |   |   |   |   |   |   hab_parkTRUE &lt;= 0: blujay (4.0)
|   |   |   |   |   |   |   hab_parkTRUE &gt; 0: tuftit (3.0/1.0)
|   |   |   |   |   |   hab_young_woodsTRUE &gt; 0
|   |   |   |   |   |   |   hab_marshTRUE &lt;= 0
|   |   |   |   |   |   |   |   hab_parkTRUE &lt;= 0
|   |   |   |   |   |   |   |   |   dogsTRUE &lt;= 0: amegfi (14.0/7.0)
|   |   |   |   |   |   |   |   |   dogsTRUE &gt; 0: blujay (5.0/3.0)
|   |   |   |   |   |   |   |   hab_parkTRUE &gt; 0: amegfi (5.0/3.0)
|   |   |   |   |   |   |   hab_marshTRUE &gt; 0: blujay (6.0/2.0)
|   |   |   |   |   hab_industrialTRUE &gt; 0
|   |   |   |   |   |   dogsTRUE &lt;= 0
|   |   |   |   |   |   |   hab_young_woodsTRUE &lt;= 0: daejun (3.0/1.0)
|   |   |   |   |   |   |   hab_young_woodsTRUE &gt; 0: amegfi (2.0/1.0)
|   |   |   |   |   |   dogsTRUE &gt; 0: amegfi (13.0/7.0)
housing_density &gt; 3
|   nearby_feedersTRUE &lt;= 0
|   |   hab_industrialTRUE &lt;= 0: blujay (2.0)
|   |   hab_industrialTRUE &gt; 0: amegfi (1.0)
|   nearby_feedersTRUE &gt; 0: tuftit (3.0/1.0)

Number of Leaves  :     49

Size of the tree :  97</code></pre>
</div>
</div>
<p>That is a lot of leaves and took a decent amount of time to run.</p>
</section>
<section id="k-nearest-neighbors" class="level3">
<h3 class="anchored" data-anchor-id="k-nearest-neighbors"><strong>K-Nearest Neighbors</strong></h3>
<p><strong>Note:</strong>&nbsp;kNN uses Euclidean distance, so data should be standardized (scaled) first. Here housing denisty are measured between 0 and 4 while all other variables are between 0 and 1. Scaling can be directly performed as preprocessing in&nbsp;<code>train</code>&nbsp;using the parameter&nbsp;<code>preProcess = "scale"</code>.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>k-Nearest Neighbors 

202 samples
 16 predictor
  5 classes: 'amegfi', 'bkcchi', 'blujay', 'daejun', 'tuftit' 

Pre-processing: scaled (16) 
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 181, 183, 181, 181, 181, 182, ... 
Resampling results across tuning parameters:

  k   Accuracy  Kappa
   1  0.677     0.523
   2  0.580     0.458
   3  0.555     0.405
   4  0.462     0.311
   5  0.505     0.360
   6  0.428     0.240
   7  0.493     0.303
   8  0.443     0.256
   9  0.452     0.187
  10  0.348     0.101

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was k = 1.</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>1-nearest neighbor model
Training set outcome distribution:

amegfi bkcchi blujay daejun tuftit 
    46     43     41     48     24 </code></pre>
</div>
</div>
<p>This appears to be our best performer so far, with accuracy of almost 65% especially as we have a k value of 3 rather than 1like the example.</p>
</section>
<section id="part-rule-based-classifier" class="level3">
<h3 class="anchored" data-anchor-id="part-rule-based-classifier"><strong>PART (Rule-based classifier)</strong></h3>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Rule-Based Classifier 

202 samples
 16 predictor
  5 classes: 'amegfi', 'bkcchi', 'blujay', 'daejun', 'tuftit' 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 181, 182, 182, 180, 182, 182, ... 
Resampling results across tuning parameters:

  threshold  pruned  Accuracy  Kappa
  0.010      yes     0.517     0.359
  0.010      no      0.590     0.425
  0.133      yes     0.548     0.357
  0.133      no      0.590     0.425
  0.255      yes     0.607     0.431
  0.255      no      0.590     0.425
  0.378      yes     0.607     0.431
  0.378      no      0.590     0.425
  0.500      yes     0.607     0.431
  0.500      no      0.590     0.425

Accuracy was used to select the optimal model using the largest value.
The final values used for the model were threshold = 0.5 and pruned = yes.</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>PART decision list
------------------

housing_density &gt; 3 AND
nearby_feedersTRUE &lt;= 0: blujay (3.0/1.0)

hab_water_freshTRUE &lt;= 0 AND
hab_marshTRUE &gt; 0 AND
hab_swampTRUE &lt;= 0: bkcchi (9.0/2.0)

hab_water_freshTRUE &lt;= 0 AND
hab_swampTRUE &gt; 0: daejun (10.0/3.0)

hab_marshTRUE &gt; 0 AND
yard_type_landscaTRUE &lt;= 0: bkcchi (7.0/3.0)

hab_marshTRUE &gt; 0 AND
hab_dcid_woodsTRUE &lt;= 0 AND
hab_young_woodsTRUE &lt;= 0: tuftit (4.0/1.0)

yard_type_landscaTRUE &lt;= 0 AND
hab_mixed_woodsTRUE &gt; 0 AND
nearby_feedersTRUE &lt;= 0 AND
hab_agriculturalTRUE &lt;= 0: bkcchi (4.0/2.0)

yard_type_landscaTRUE &lt;= 0 AND
hab_mixed_woodsTRUE &gt; 0: amegfi (6.0/3.0)

hab_marshTRUE &gt; 0 AND
hab_dcid_woodsTRUE &gt; 0 AND
hab_swampTRUE &lt;= 0 AND
hab_young_woodsTRUE &gt; 0 AND
catsTRUE &lt;= 0: amegfi (6.0/3.0)

hab_marshTRUE &gt; 0 AND
nearby_feedersTRUE &lt;= 0 AND
hab_dcid_woodsTRUE &gt; 0: blujay (4.0)

housing_density &lt;= 3 AND
hab_water_freshTRUE &lt;= 0 AND
yard_type_landscaTRUE &gt; 0 AND
hab_industrialTRUE &gt; 0 AND
housing_density &gt; 1 AND
hab_agriculturalTRUE &lt;= 0 AND
hab_parkTRUE &gt; 0: daejun (10.0/5.0)

housing_density &lt;= 3 AND
hab_parkTRUE &lt;= 0 AND
yard_type_landscaTRUE &gt; 0 AND
yard_type_woodsTRUE &lt;= 0: daejun (9.0/3.0)

housing_density &lt;= 3 AND
humansTRUE &lt;= 0 AND
nearby_feedersTRUE &lt;= 0: blujay (5.0/2.0)

housing_density &lt;= 3 AND
humansTRUE &gt; 0 AND
hab_agriculturalTRUE &gt; 0 AND
dogsTRUE &lt;= 0 AND
nearby_feedersTRUE &gt; 0 AND
hab_marshTRUE &lt;= 0: amegfi (11.0/4.0)

housing_density &lt;= 3 AND
humansTRUE &gt; 0 AND
hab_water_freshTRUE &lt;= 0 AND
hab_parkTRUE &lt;= 0 AND
dogsTRUE &lt;= 0: daejun (5.0)

housing_density &lt;= 3 AND
humansTRUE &lt;= 0: bkcchi (4.0/1.0)

housing_density &lt;= 3 AND
hab_agriculturalTRUE &gt; 0 AND
dogsTRUE &lt;= 0 AND
yard_type_woodsTRUE &lt;= 0: blujay (4.0/1.0)

hab_water_freshTRUE &lt;= 0 AND
housing_density &lt;= 1 AND
hab_young_woodsTRUE &lt;= 0: bkcchi (7.0/2.0)

housing_density &lt;= 3 AND
hab_water_freshTRUE &lt;= 0 AND
hab_young_woodsTRUE &lt;= 0 AND
yard_type_woodsTRUE &gt; 0 AND
hab_mixed_woodsTRUE &gt; 0 AND
hab_industrialTRUE &gt; 0: amegfi (4.0/1.0)

humansTRUE &gt; 0 AND
hab_water_freshTRUE &lt;= 0 AND
hab_parkTRUE &gt; 0: amegfi (15.0/8.0)

hab_water_freshTRUE &gt; 0 AND
hab_mixed_woodsTRUE &lt;= 0 AND
hab_industrialTRUE &lt;= 0 AND
hab_young_woodsTRUE &lt;= 0: daejun (8.0/4.0)

hab_water_freshTRUE &gt; 0 AND
hab_mixed_woodsTRUE &gt; 0 AND
yard_type_woodsTRUE &gt; 0 AND
humansTRUE &gt; 0 AND
dogsTRUE &gt; 0 AND
catsTRUE &lt;= 0 AND
hab_marshTRUE &lt;= 0 AND
hab_dcid_woodsTRUE &gt; 0 AND
housing_density &lt;= 1 AND
hab_industrialTRUE &lt;= 0: blujay (10.0/5.0)

hab_water_freshTRUE &gt; 0 AND
hab_mixed_woodsTRUE &gt; 0 AND
yard_type_woodsTRUE &gt; 0 AND
humansTRUE &gt; 0 AND
dogsTRUE &gt; 0 AND
hab_marshTRUE &lt;= 0 AND
hab_young_woodsTRUE &lt;= 0 AND
hab_dcid_woodsTRUE &gt; 0: amegfi (8.0/4.0)

hab_water_freshTRUE &gt; 0 AND
hab_mixed_woodsTRUE &gt; 0 AND
nearby_feedersTRUE &lt;= 0 AND
hab_marshTRUE &lt;= 0: amegfi (15.0/9.0)

hab_water_freshTRUE &lt;= 0: daejun (7.0/2.0)

hab_industrialTRUE &gt; 0 AND
hab_mixed_woodsTRUE &gt; 0 AND
humansTRUE &gt; 0 AND
hab_agriculturalTRUE &lt;= 0: daejun (4.0/1.0)

hab_dcid_woodsTRUE &gt; 0 AND
hab_industrialTRUE &lt;= 0: tuftit (4.0/1.0)

hab_mixed_woodsTRUE &gt; 0 AND
hab_dcid_woodsTRUE &lt;= 0 AND
hab_agriculturalTRUE &gt; 0: blujay (7.0/5.0)

hab_dcid_woodsTRUE &gt; 0 AND
hab_mixed_woodsTRUE &gt; 0: blujay (4.0/1.0)

hab_mixed_woodsTRUE &lt;= 0: tuftit (4.0/1.0)

: bkcchi (4.0/1.0)

Number of Rules  :  30</code></pre>
</div>
</div>
<p>That is a lot of rules and it took awhile to run. The accuracy scores are not as high as k nearest but better than the others.</p>
</section>
<section id="linear-support-vector-machines" class="level3">
<h3 class="anchored" data-anchor-id="linear-support-vector-machines"><strong>Linear Support Vector Machines</strong></h3>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Support Vector Machines with Linear Kernel 

202 samples
 16 predictor
  5 classes: 'amegfi', 'bkcchi', 'blujay', 'daejun', 'tuftit' 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 181, 183, 181, 182, 182, 183, ... 
Resampling results:

  Accuracy  Kappa
  0.43      0.151

Tuning parameter 'C' was held constant at a value of 1</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Support Vector Machine object of class "ksvm" 

SV type: C-svc  (classification) 
 parameter : cost C = 1 

Linear (vanilla) kernel function. 

Number of Support Vectors : 193 

Objective Function Value : -54.1 -59.4 -64.6 -36.4 -56.4 -53.1 -34.6 -54.7 -41.4 -35.5 
Training error : 0.509901 </code></pre>
</div>
</div>
<p>This is a fairly low accuracy and high training error. This may be the worst performer yet.</p>
</section>
<section id="random-forest" class="level3">
<h3 class="anchored" data-anchor-id="random-forest"><strong>Random Forest</strong></h3>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest 

202 samples
 16 predictor
  5 classes: 'amegfi', 'bkcchi', 'blujay', 'daejun', 'tuftit' 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 182, 183, 181, 182, 181, 183, ... 
Resampling results across tuning parameters:

  mtry  Accuracy  Kappa
   2    0.638     0.470
   5    0.668     0.499
   9    0.648     0.495
  12    0.672     0.521
  16    0.713     0.579

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was mtry = 16.</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
 randomForest(x = x, y = y, mtry = param$mtry) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 16

        OOB estimate of  error rate: 67.3%
Confusion matrix:
       amegfi bkcchi blujay daejun tuftit class.error
amegfi     15      8     11      9      3       0.674
bkcchi      9     16      5      9      4       0.628
blujay     11      7     11      7      5       0.732
daejun      9     10      7     20      2       0.583
tuftit      8      3      6      3      4       0.833</code></pre>
</div>
</div>
<p>The mtry is 16 and the OOB are all over 60% so I would guess that this is overfiting the data</p>
</section>
<section id="gradient-boosted-decision-trees-xgboost" class="level3">
<h3 class="anchored" data-anchor-id="gradient-boosted-decision-trees-xgboost"><strong>Gradient Boosted Decision Trees (xgboost)</strong></h3>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>eXtreme Gradient Boosting 

202 samples
 16 predictor
  5 classes: 'amegfi', 'bkcchi', 'blujay', 'daejun', 'tuftit' 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 182, 181, 182, 183, 181, 181, ... 
Resampling results:

  Accuracy  Kappa
  0.5       0.274

Tuning parameter 'nrounds' was held constant at a value of 20
Tuning
 held constant at a value of 1
Tuning parameter 'subsample' was held
 constant at a value of 0.5</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>##### xgb.Booster
raw: 109.9 Kb 
call:
  xgboost::xgb.train(params = list(eta = param$eta, max_depth = param$max_depth, 
    gamma = param$gamma, colsample_bytree = param$colsample_bytree, 
    min_child_weight = param$min_child_weight, subsample = param$subsample), 
    data = x, nrounds = param$nrounds, num_class = length(lev), 
    objective = "multi:softprob")
params (as set within xgb.train):
  eta = "0.1", max_depth = "3", gamma = "0", colsample_bytree = "0.6", min_child_weight = "1", subsample = "0.5", num_class = "5", objective = "multi:softprob", validate_parameters = "TRUE"
xgb.attributes:
  niter
callbacks:
  cb.print.evaluation(period = print_every_n)
# of features: 16 
niter: 20
nfeatures : 16 
xNames : yard_type_landscaTRUE yard_type_woodsTRUE hab_dcid_woodsTRUE hab_mixed_woodsTRUE hab_parkTRUE hab_water_freshTRUE hab_industrialTRUE hab_agriculturalTRUE hab_young_woodsTRUE hab_swampTRUE hab_marshTRUE nearby_feedersTRUE catsTRUE dogsTRUE humansTRUE housing_density 
problemType : Classification 
tuneValue :
      nrounds max_depth eta gamma colsample_bytree min_child_weight subsample
1      20         3 0.1     0              0.6                1       0.5
obsLevels : amegfi bkcchi blujay daejun tuftit 
param :
    list()</code></pre>
</div>
</div>
</section>
<section id="artificial-neural-network" class="level3">
<h3 class="anchored" data-anchor-id="artificial-neural-network"><strong>Artificial Neural Network</strong></h3>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Neural Network 

202 samples
 16 predictor
  5 classes: 'amegfi', 'bkcchi', 'blujay', 'daejun', 'tuftit' 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 183, 180, 182, 182, 181, 182, ... 
Resampling results across tuning parameters:

  size  decay  Accuracy  Kappa
  1     0e+00  0.410     0.112
  1     1e-04  0.452     0.173
  1     1e-03  0.402     0.202
  1     1e-02  0.427     0.144
  1     1e-01  0.415     0.155
  3     0e+00  0.558     0.344
  3     1e-04  0.357     0.198
  3     1e-03  0.455     0.238
  3     1e-02  0.468     0.296
  3     1e-01  0.533     0.347
  5     0e+00  0.618     0.412
  5     1e-04  0.495     0.271
  5     1e-03  0.568     0.335
  5     1e-02  0.627     0.468
  5     1e-01  0.657     0.491
  7     0e+00  0.553     0.373
  7     1e-04  0.623     0.466
  7     1e-03  0.632     0.469
  7     1e-02  0.695     0.561
  7     1e-01  0.573     0.411
  9     0e+00  0.647     0.497
  9     1e-04  0.622     0.475
  9     1e-03  0.618     0.425
  9     1e-02  0.618     0.439
  9     1e-01  0.622     0.452

Accuracy was used to select the optimal model using the largest value.
The final values used for the model were size = 7 and decay = 0.01.</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>a 16-7-5 network with 159 weights
inputs: yard_type_landscaTRUE yard_type_woodsTRUE hab_dcid_woodsTRUE hab_mixed_woodsTRUE hab_parkTRUE hab_water_freshTRUE hab_industrialTRUE hab_agriculturalTRUE hab_young_woodsTRUE hab_swampTRUE hab_marshTRUE nearby_feedersTRUE catsTRUE dogsTRUE humansTRUE housing_density 
output(s): .outcome 
options were - softmax modelling  decay=0.01</code></pre>
</div>
</div>
<p>These results are more promising that others. Lets Compare the Models and add some commentary.</p>
</section>
</section>
<section id="comparing-models" class="level2">
<h2 class="anchored" data-anchor-id="comparing-models"><strong>Comparing Models</strong></h2>
<p>Collect the performance metrics from the models trained on the same data.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
resamples.default(x = list(ctree = ctreeFit, C45 = C45Fit, SVM = svmFit, KNN
 = knnFit, rules = rulesFit, randomForest = randomForestFit, xgboost
 = xgboostFit, NeuralNet = nnetFit))

Models: ctree, C45, SVM, KNN, rules, randomForest, xgboost, NeuralNet 
Number of resamples: 10 
Performance metrics: Accuracy, Kappa 
Time estimates for: everything, final model fit </code></pre>
</div>
</div>
<p>Calculate summary statistics</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
summary.resamples(object = resamps)

Models: ctree, C45, SVM, KNN, rules, randomForest, xgboost, NeuralNet 
Number of resamples: 10 

Accuracy 
              Min. 1st Qu. Median  Mean 3rd Qu. Max. NA's
ctree        0.000   0.271  0.500 0.470   0.713  0.8    0
C45          0.000   0.425  0.600 0.565   0.729  1.0    0
SVM          0.000   0.250  0.500 0.430   0.575  1.0    0
KNN          0.400   0.500  0.708 0.677   0.788  1.0    0
rules        0.000   0.525  0.633 0.607   0.750  1.0    0
randomForest 0.400   0.617  0.708 0.713   0.788  1.0    0
xgboost      0.250   0.400  0.450 0.500   0.625  0.8    0
NeuralNet    0.333   0.525  0.708 0.695   0.800  1.0    0

Kappa 
                Min. 1st Qu. Median  Mean 3rd Qu.  Max. NA's
ctree        -0.0714   0.000 0.1000 0.239   0.512 0.667    0
C45          -0.3333   0.213 0.4097 0.379   0.534 1.000    0
SVM          -0.1613  -0.135 0.0312 0.151   0.318 1.000    0
KNN           0.1176   0.294 0.5227 0.523   0.650 1.000    0
rules        -0.2000   0.244 0.4375 0.431   0.625 1.000    0
randomForest  0.0625   0.416 0.5470 0.579   0.708 1.000    0
xgboost       0.0000   0.124 0.2053 0.274   0.472 0.583    0
NeuralNet     0.2000   0.361 0.5227 0.561   0.708 1.000    0</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>So it does appear that the random forest was one of the best performers but I think this is a case of overfiting.</p>
<p>Perform inference about differences between models. For each metric, all pair-wise differences are computed and tested to assess if the difference is equal to zero. By default Bonferroni correction for multiple comparison is used. Differences are shown in the upper triangle and p-values are in the lower triangle.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
diff.resamples(x = resamps)

Models: ctree, C45, SVM, KNN, rules, randomForest, xgboost, NeuralNet 
Metrics: Accuracy, Kappa 
Number of differences: 28 
p-value adjustment: bonferroni </code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
summary.diff.resamples(object = difs)

p-value adjustment: bonferroni 
Upper diagonal: estimates of the difference
Lower diagonal: p-value for H0: difference = 0

Accuracy 
             ctree  C45     SVM     KNN     rules   randomForest xgboost
ctree               -0.0950  0.0400 -0.2067 -0.1367 -0.2433      -0.0300
C45          1.0000          0.1350 -0.1117 -0.0417 -0.1483       0.0650
SVM          1.0000 1.0000          -0.2467 -0.1767 -0.2833      -0.0700
KNN          1.0000 1.0000  1.0000           0.0700 -0.0367       0.1767
rules        1.0000 1.0000  1.0000  1.0000          -0.1067       0.1067
randomForest 0.7100 1.0000  0.9455  1.0000  1.0000                0.2133
xgboost      1.0000 1.0000  1.0000  0.9534  1.0000  0.0139              
NeuralNet    0.8851 1.0000  1.0000  1.0000  1.0000  1.0000       0.0791 
             NeuralNet
ctree        -0.2250  
C45          -0.1300  
SVM          -0.2650  
KNN          -0.0183  
rules        -0.0883  
randomForest  0.0183  
xgboost      -0.1950  
NeuralNet             

Kappa 
             ctree  C45     SVM     KNN     rules   randomForest xgboost
ctree               -0.1402  0.0883 -0.2837 -0.1917 -0.3403      -0.0350
C45          1.0000          0.2285 -0.1435 -0.0514 -0.2001       0.1052
SVM          1.0000 1.0000          -0.3720 -0.2800 -0.4286      -0.1233
KNN          0.9835 1.0000  0.4451           0.0921 -0.0566       0.2488
rules        1.0000 1.0000  1.0000  1.0000          -0.1487       0.1567
randomForest 0.3912 1.0000  0.5497  1.0000  1.0000                0.3053
xgboost      1.0000 1.0000  1.0000  1.0000  1.0000  0.0324              
NeuralNet    0.1051 1.0000  0.4724  1.0000  1.0000  1.0000       0.0554 
             NeuralNet
ctree        -0.3223  
C45          -0.1821  
SVM          -0.4106  
KNN          -0.0386  
rules        -0.1307  
randomForest  0.0180  
xgboost      -0.2873  
NeuralNet             </code></pre>
</div>
</div>
<p>It is hard to tell which one of these models performed the best or the worst as they were all pretty bad. All of the p-values indicate that we cannot reject the null hypothesis of the difference = 0 and the differences in the rows are mostly negative.</p>
</section>
<section id="applying-the-chosen-model-to-the-test-data" class="level2">
<h2 class="anchored" data-anchor-id="applying-the-chosen-model-to-the-test-data"><strong>Applying the Chosen Model to the Test Data</strong></h2>
<p>Most models do similarly well on the data. We choose here the random forest model.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code> [1] daejun daejun daejun daejun blujay daejun blujay daejun blujay bkcchi
[11] amegfi daejun daejun amegfi daejun tuftit daejun amegfi daejun blujay
[21] amegfi daejun amegfi bkcchi daejun tuftit bkcchi bkcchi bkcchi amegfi
[31] bkcchi bkcchi bkcchi bkcchi amegfi daejun blujay daejun amegfi amegfi
[41] bkcchi bkcchi tuftit tuftit daejun bkcchi bkcchi bkcchi
Levels: amegfi bkcchi blujay daejun tuftit</code></pre>
</div>
</div>
<p>Calculate the confusion matrix for the held-out test data.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction amegfi bkcchi blujay daejun tuftit
    amegfi      2      1      3      1      2
    bkcchi      5      5      2      2      0
    blujay      1      0      2      0      2
    daejun      1      3      3      8      1
    tuftit      2      1      0      1      0

Overall Statistics
                                        
               Accuracy : 0.354         
                 95% CI : (0.222, 0.505)
    No Information Rate : 0.25          
    P-Value [Acc &gt; NIR] : 0.0704        
                                        
                  Kappa : 0.175         
                                        
 Mcnemar's Test P-Value : 0.2941        

Statistics by Class:

                     Class: amegfi Class: bkcchi Class: blujay Class: daejun
Sensitivity                 0.1818         0.500        0.2000         0.667
Specificity                 0.8108         0.763        0.9211         0.778
Pos Pred Value              0.2222         0.357        0.4000         0.500
Neg Pred Value              0.7692         0.853        0.8140         0.875
Prevalence                  0.2292         0.208        0.2083         0.250
Detection Rate              0.0417         0.104        0.0417         0.167
Detection Prevalence        0.1875         0.292        0.1042         0.333
Balanced Accuracy           0.4963         0.632        0.5605         0.722
                     Class: tuftit
Sensitivity                 0.0000
Specificity                 0.9070
Pos Pred Value              0.0000
Neg Pred Value              0.8864
Prevalence                  0.1042
Detection Rate              0.0000
Detection Prevalence        0.0833
Balanced Accuracy           0.4535</code></pre>
</div>
</div>
<p>Not great with an accuracy of 35% and the p-value is not significant. The negative pred was high but the pos pred value was pretty low.</p>
<p>Can we predict the presence or absence of a specific bird species based on habitat type, surrounding environment (like presence of squirrels, cats, humans, etc.), and feeding habits in a given location?</p>
<p>I would that the answer is no. However, I limited the data I was considering and the species. I may have gotten different results if I had chosen other bird species or logical(true /false) variable. But for these 5 species and these 16 variable about the habitat and surrounding area the answer is no.</p>
</section>
<section id="comparing-decision-boundaries-of-popular-classification-techniques" class="level2">
<h2 class="anchored" data-anchor-id="comparing-decision-boundaries-of-popular-classification-techniques"><strong>Comparing Decision Boundaries of Popular Classification Techniques</strong></h2>
<p>Classifiers create decision boundaries to discriminate between classes. Different classifiers are able to create different shapes of decision boundaries (e.g., some are strictly linear) and thus some classifiers may perform better for certain datasets. This page visualizes the decision boundaries found by several popular classification methods.</p>
<p>The following plot adds the decision boundary (black lines) and classification confidence (color intensity) by evaluating the classifier at evenly spaced grid points. Note that low resolution (to make evaluation faster) will make the decision boundary look like it has small steps even if it is a (straight) line.</p>
<section id="not-penguins-dataset-but-i-will-use-birds" class="level3">
<h3 class="anchored" data-anchor-id="not-penguins-dataset-but-i-will-use-birds"><strong>Not Penguins Dataset but I will use Birds</strong></h3>
<p>Instead of the penguins dataset I will use the bird species by longitude and latitude as the two dimensions</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 151 × 3
   latitude longitude species_code
      &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;       
 1     43.6     -83.9 bkcchi      
 2     41.5     -90.7 bkcchi      
 3     44.7     -86.2 daejun      
 4     44.2     -69.8 blujay      
 5     40.3     -79.8 blujay      
 6     37.7    -122.  daejun      
 7     45.1     -64.6 blujay      
 8     40.4     -75.4 daejun      
 9     44.2     -81.0 daejun      
10     42.8     -89.1 daejun      
# ℹ 141 more rows</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-36-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>I am really feeling like I have chosen the wrong data set.</p>
<section id="k-nearest-neighbors-classifier" class="level4">
<h4 class="anchored" data-anchor-id="k-nearest-neighbors-classifier">K-Nearest Neighbors Classifier</h4>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-37-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>I literally just laughed out loud at this.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-38-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-39-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>I do not think increasing k helped in this situation.</p>
</section>
<section id="naive-bayes-classifier" class="level4">
<h4 class="anchored" data-anchor-id="naive-bayes-classifier">Naive Bayes Classifier</h4>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-40-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>I think that looks better than the previous experiment, even though the accuracy is lower.</p>
</section>
<section id="linear-discriminant-analysis" class="level4">
<h4 class="anchored" data-anchor-id="linear-discriminant-analysis">Linear Discriminant Analysis</h4>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-41-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="multinomial-logistic-regression-implemented-in-nnet" class="level4">
<h4 class="anchored" data-anchor-id="multinomial-logistic-regression-implemented-in-nnet">Multinomial Logistic Regression (implemented in nnet)</h4>
<p>Multinomial logistic regression is an extension of logistic regression to problems with more than two classes.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code># weights:  12 (6 variable)
initial  value 165.890456 
iter  10 value 157.836568
final  value 157.523643 
converged</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-43-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="decision-trees" class="level4">
<h4 class="anchored" data-anchor-id="decision-trees">Decision Trees</h4>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-44-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-45-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Some of this really looks like artwork.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-46-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-47-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>That is definitely overfitted</p>
</section>
<section id="svm" class="level4">
<h4 class="anchored" data-anchor-id="svm">SVM</h4>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Computation failed in `stat_contour()`
Caused by error in `if (zero_range(range)) ...`:
! missing value where TRUE/FALSE needed</code></pre>
</div>
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-48-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Interesting that this one just decided to predict everything as one species and got an accuracy of 40%.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-49-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-50-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-51-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="single-layer-feed-forward-neural-networks" class="level4">
<h4 class="anchored" data-anchor-id="single-layer-feed-forward-neural-networks">Single Layer Feed-forward Neural Networks</h4>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Computation failed in `stat_contour()`
Caused by error in `if (zero_range(range)) ...`:
! missing value where TRUE/FALSE needed</code></pre>
</div>
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-52-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Computation failed in `stat_contour()`
Caused by error in `if (zero_range(range)) ...`:
! missing value where TRUE/FALSE needed</code></pre>
</div>
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-53-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-54-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-55-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<p><img src="hw-03_part2_files/figure-html/unnamed-chunk-56-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This data of the three species of birds has no clusters or groupings. The models show that the accuracy on models that are not overfited are below 50%.</p>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>